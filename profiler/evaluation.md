# 测试样例
## 影响缓存效果的因素
- 不同分布的图数据集
- 图划分算法
- batch size
- 缓存架构
- 采样算法
## 图分布
分布倾斜程度的指标
## 静态缓存
> 优点：幂律分布图效果好  
> 缺点：batch_size增大效果急剧下降  

利用图的幂律分布，将最频繁访问的一部分节点缓存至GPU  
在多GPU的情况下，利用GPU间通信减少CPU和GPU之间的PCIe通信，降低对CPU资源的争用  
采样一律在GPU上进行，或者CPU/GPU混合采样
### 度
按度排序，获取节点在不同GPU上的权重，从头开始遍历，按照权重大小将节点缓存至不同的GPU  
此种方法的关键点在于节点在不同GPU上的分配策略  
我尝试获取batch的一阶邻居并统计其频率，作为在不同GPU上的权重才进行缓存分配，但差距不大
### 预采样
预采样若干轮统计节点访问频率，按不同GPU上的访问频率排序后，将最前面的部分缓存至显存  
这样的问题在于多个GPU之间缓存的数据重复率太高，不能很好地扩展缓存空间  
### PageRank
### 综合评价指标

## 动态缓存
### FIFO
- FIFO开销较低，特定情况下与PaGraph效果相当
- FIFO缓存替换每个minibatch进行一次
## 组合策略
- 进行预训练和对图的预处理来确定具体的缓存策略
- 动态缓存和静态缓存的比例划分指标 从图的幂律分布入手

## 测试
### 相邻若干个batch或子图间的重复性
### 再对比几个大型图数据集
### 新建一个可修改的配置文件 yaml或者其他

# 分区算法
- 分区算法的时间复杂度 是否随着图数据集规模的增大指数级增长
- 不同分区之间的冗余带来的开销
## Lin-Kernighan算法

# 数据集
ogbn-products
ogbn-papers100M
Reddit
WikiKG90M

# todo
- [ ] **度排序后的前百分之多少，的度之和达到了度总数的百分之多少** 
- [ ] 预采样频率排序的百分比分布图
- [ ] 分区算法的 **数据集-开销**图